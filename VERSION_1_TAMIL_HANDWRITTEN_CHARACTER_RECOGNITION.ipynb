{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EHJxAjBraokc"
      },
      "outputs": [],
      "source": [
        "# Load all necessary Packages\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import initializers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# supporting libraries\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pickle\n",
        "import h5py\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "3tB6f8L7cuy6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "IMAGE_SIZE =(32, 32)  # Assuming input images are grayscale # Size to which images will be resized\n",
        "NUM_CLASSES = 12  # Number of classes (subfolders)"
      ],
      "metadata": {
        "id": "5Q6p22F9dGuf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and augment images\n",
        "def preprocess_and_augment(image):\n",
        "    # Resize image\n",
        "    resized_image = cv2.resize(image, IMAGE_SIZE)\n",
        "    # Convert to grayscale\n",
        "    grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "    # Normalize pixel values\n",
        "    normalized_image = grayscale_image / 255.0\n",
        "    return normalized_image\n"
      ],
      "metadata": {
        "id": "ACql-4wnee1w"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Degree range for random rotations\n",
        "    width_shift_range=0.1,  # Fraction of total width for horizontal shifts\n",
        "    height_shift_range=0.1,  # Fraction of total height for vertical shifts\n",
        "    shear_range=0.2,  # Shear angle in counter-clockwise direction\n",
        "    zoom_range=0.2,  # Range for random zoom\n",
        "    horizontal_flip=True,  # Randomly flip inputs horizontally\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        ")\n"
      ],
      "metadata": {
        "id": "od6cTN_qehv1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images from folders\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for class_index in range(NUM_CLASSES):\n",
        "        class_dir = os.path.join(data_dir, str(class_index))\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_name)\n",
        "            image = cv2.imread(image_path)\n",
        "            preprocessed_image = preprocess_and_augment(image)\n",
        "            images.append(preprocessed_image)\n",
        "            labels.append(class_index)\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "0rrpPE8CemFX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "train_data_dir = \"/content/drive/MyDrive/HANDWRITTENTAMILCHARACTERS/processed/train\"  # Replace with your train folder path\n",
        "X_train, y_train = load_data(train_data_dir)\n"
      ],
      "metadata": {
        "id": "-dbpoEDzeqKy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "shuffle_indices = np.random.permutation(len(X_train))\n",
        "X_train = X_train[shuffle_indices]\n",
        "y_train = y_train[shuffle_indices]"
      ],
      "metadata": {
        "id": "rOazZ_WKe4lJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model(input_shape):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "V4aNuFiRfiZq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n"
      ],
      "metadata": {
        "id": "Xerl2qhGfuQZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTD0WGOKf59G",
        "outputId": "f38e2a4d-71ee-4616-fc05-f3323985c152"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_cnn_model(input_shape)\n"
      ],
      "metadata": {
        "id": "0DthQeRjf77U"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HVfpj0ohQhC",
        "outputId": "17cc0718-9190-47cc-e628-ac018af3aede"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                65600     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                780       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122124 (477.05 KB)\n",
            "Trainable params: 122124 (477.05 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Q2QonQW-haEm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khXIgMeKhgYg",
        "outputId": "78a37831-29ce-4d2f-ffa0-a8b9737176fb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "102/102 [==============================] - 5s 34ms/step - loss: 1.9433 - accuracy: 0.3236 - val_loss: 1.2807 - val_accuracy: 0.5670\n",
            "Epoch 2/10\n",
            "102/102 [==============================] - 4s 43ms/step - loss: 0.9873 - accuracy: 0.6850 - val_loss: 0.7948 - val_accuracy: 0.7491\n",
            "Epoch 3/10\n",
            "102/102 [==============================] - 4s 37ms/step - loss: 0.6699 - accuracy: 0.7831 - val_loss: 0.7477 - val_accuracy: 0.7638\n",
            "Epoch 4/10\n",
            "102/102 [==============================] - 3s 32ms/step - loss: 0.5019 - accuracy: 0.8321 - val_loss: 0.5197 - val_accuracy: 0.8266\n",
            "Epoch 5/10\n",
            "102/102 [==============================] - 3s 32ms/step - loss: 0.3714 - accuracy: 0.8770 - val_loss: 0.5002 - val_accuracy: 0.8278\n",
            "Epoch 6/10\n",
            "102/102 [==============================] - 5s 47ms/step - loss: 0.2995 - accuracy: 0.9000 - val_loss: 0.3408 - val_accuracy: 0.8881\n",
            "Epoch 7/10\n",
            "102/102 [==============================] - 3s 32ms/step - loss: 0.2437 - accuracy: 0.9194 - val_loss: 0.3208 - val_accuracy: 0.8942\n",
            "Epoch 8/10\n",
            "102/102 [==============================] - 3s 32ms/step - loss: 0.1945 - accuracy: 0.9320 - val_loss: 0.3335 - val_accuracy: 0.8831\n",
            "Epoch 9/10\n",
            "102/102 [==============================] - 3s 32ms/step - loss: 0.1763 - accuracy: 0.9373 - val_loss: 0.2660 - val_accuracy: 0.9016\n",
            "Epoch 10/10\n",
            "102/102 [==============================] - 5s 48ms/step - loss: 0.1371 - accuracy: 0.9529 - val_loss: 0.3084 - val_accuracy: 0.8893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d4827388bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
        "    resized_image = cv2.resize(image, (32, 32))  # Resize image to (32, 32)\n",
        "    normalized_image = resized_image / 255.0  # Normalize pixel values\n",
        "    return np.expand_dims(normalized_image, axis=-1)  # Add channel dimension"
      ],
      "metadata": {
        "id": "dUfg7X_lhsQx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image for prediction\n",
        "image_path = '/content/drive/MyDrive/HANDWRITTENTAMILCHARACTERS/processed/test/7/01720.tiff'  # Replace with the path to your image\n",
        "input_image = preprocess_image(image_path)"
      ],
      "metadata": {
        "id": "eCSxiMFxh95j"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "prediction = model.predict(np.array([input_image]))\n",
        "predicted_class_index = np.argmax(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2218w5DiCNK",
        "outputId": "f054b5b7-35c3-4c97-ccce-e2b927fcc2e6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the predicted class index\n",
        "print(\"Predicted class index:\", predicted_class_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBcv_mfoiE3Y",
        "outputId": "e32d80e6-059d-4db7-a8d3-fd127f26aeae"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and resize a single image (TIFF)\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Could not read image file: {image_path}\")\n",
        "    resized_image = cv2.resize(image, (32, 32))  # Resize image to (32, 32)\n",
        "    normalized_image = resized_image / 255.0  # Normalize pixel values\n",
        "    return np.expand_dims(normalized_image, axis=-1)  # Add channel dimension\n"
      ],
      "metadata": {
        "id": "xuvn3bWHiTkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"tamil_handwritten_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsI4L_u-lPhu",
        "outputId": "3f5b4ef6-82c8-4517-df10-77824782e465"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Path to the model file in Google Colab\n",
        "colab_model_path = 'tamil_handwritten_model.h5'\n",
        "\n",
        "# Download the file\n",
        "files.download(colab_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "J71YLpMUlYgm",
        "outputId": "c108c95d-d84c-4307-b215-02250ddf95c7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9c7baaee-ad97-4380-b5bd-bcc00b08ea5f\", \"tamil_handwritten_model.h5\", 1517656)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}